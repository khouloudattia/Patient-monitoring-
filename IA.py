# -*- coding: utf-8 -*-
"""Untitled11.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RGgxQKa6X_PdVKr8U6xGqETNkJK1FpnL
"""

import warnings
warnings.filterwarnings('ignore')

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# %matplotlib inline

df = pd.read_csv('/content/feed (3).csv')
df.head(80)

df.info()

print('Number of rows in the dataset: ',df.shape[0])
print('Number of columns in the dataset: ',df.shape[1])

df.isnull().sum()

df.describe()

df.drop('created_at', inplace=True, axis=1)

df.head()

sns.set_style('whitegrid')

plt.figure(figsize=(10,10))
sns.heatmap(df.corr(), annot = True, cmap='coolwarm',linewidths=.1)
plt.show()

sns.distplot(df['field1'],kde=False,bins=73,color='violet')

sns.distplot(df['field2'],kde=False,bins=73,color='blue')
plt.show()

plt.figure(figsize=(10,10))
sns.scatterplot(x='field1',y='field2',data=df,hue='field1')
plt.show()

X= df.drop('field2',axis=1)
y=df['field2']

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=.3,random_state=42)

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()

X_train_scaled = scaler.fit_transform(X_train)
X_train = pd.DataFrame(X_train_scaled)

X_test_scaled = scaler.transform(X_test)
X_test = pd.DataFrame(X_test_scaled)

from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import GridSearchCV
knn =KNeighborsClassifier()
params = {'n_neighbors':list(range(1,20)),
    'p':[1, 2, 3, 4,5,6,7,8,9,10],
    'leaf_size':list(range(1,20)),
    'weights':['uniform', 'distance']
         }

model = GridSearchCV(knn,params,cv=3, n_jobs=-1)

model.get_params().keys()

model.fit(X_train,y_train)
model.best_params_

predict = model.predict(X_test)

from sklearn.metrics import accuracy_score,confusion_matrix
print('Accuracy Score: ',accuracy_score(y_test,predict))
print('Using k-NN we get an accuracy score of: ',
      round(accuracy_score(y_test,predict),5)*100,'%')

cnf_matrix = confusion_matrix(y_test,predict)
cnf_matrix

class_names = [0,1]
fig,ax = plt.subplots()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks,class_names)
plt.yticks(tick_marks,class_names)

#create a heat map
sns.heatmap(pd.DataFrame(cnf_matrix), annot = True, cmap = 'YlGnBu',
           fmt = 'g')
ax.xaxis.set_label_position('top')
plt.tight_layout()
plt.title('Confusion matrix for k-Nearest Neighbors Model', y = 1.1)
plt.ylabel('Actual label')
plt.xlabel('Predicted label')
plt.show()

from sklearn.metrics import classification_report

print(classification_report(y_test,predict))

import seaborn as sns
sns.countplot(y_test)